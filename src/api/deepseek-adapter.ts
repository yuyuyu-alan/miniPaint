/**
 * DeepSeek LLM é€‚é…å™¨
 * å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºå›¾åƒç¼–è¾‘APIè°ƒç”¨
 */

import OpenAI from 'openai'
import { createLLMInterface } from './llm-bridge'
import type { AICommand } from './ai-interface'

// DeepSeeké…ç½®æ¥å£
interface DeepSeekConfig {
  apiKey: string
  baseURL?: string
  model?: string
  maxTokens?: number
  temperature?: number
}

// é»˜è®¤é…ç½®
const DEFAULT_CONFIG: Partial<DeepSeekConfig> = {
  baseURL: 'https://api.deepseek.com',
  model: 'deepseek-chat',
  maxTokens: 2000,
  temperature: 0.7
}

// å‘½ä»¤è§£æç»“æœ
interface ParsedCommands {
  success: boolean
  commands: AICommand[]
  explanation: string
  error?: string
}

/**
 * DeepSeeké€‚é…å™¨ç±»
 */
export class DeepSeekAdapter {
  private openai: OpenAI
  private llmInterface: ReturnType<typeof createLLMInterface>
  private config: DeepSeekConfig

  constructor(config: DeepSeekConfig) {
    this.config = { ...DEFAULT_CONFIG, ...config }
    
    this.openai = new OpenAI({
      baseURL: this.config.baseURL,
      apiKey: this.config.apiKey
    })
    
    this.llmInterface = createLLMInterface()
  }

  /**
   * ç³»ç»Ÿæç¤ºè¯ - å®šä¹‰AIå¦‚ä½•ç†è§£å’Œè½¬æ¢ç”¨æˆ·æŒ‡ä»¤
   */
  private getSystemPrompt(): string {
    return `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒç¼–è¾‘AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºå…·ä½“çš„å›¾åƒç¼–è¾‘APIè°ƒç”¨ã€‚

å¯ç”¨çš„APIå‘½ä»¤åŒ…æ‹¬ï¼š

**ç”»å¸ƒæ“ä½œï¼š**
- setCanvasSize(width, height) - è®¾ç½®ç”»å¸ƒå°ºå¯¸
- setBackgroundColor(color) - è®¾ç½®èƒŒæ™¯è‰²
- getCanvasState() - è·å–ç”»å¸ƒçŠ¶æ€
- exportCanvas(format, quality) - å¯¼å‡ºç”»å¸ƒ

**å›¾å±‚ç®¡ç†ï¼š**
- createLayer(name, type) - åˆ›å»ºå›¾å±‚ (type: 'raster'|'vector'|'text')
- deleteLayer(layerId) - åˆ é™¤å›¾å±‚
- setLayerOpacity(layerId, opacity) - è®¾ç½®é€æ˜åº¦ (0-100)

**ç»˜å›¾æ“ä½œï¼š**
- drawRectangle(x, y, width, height, options) - ç»˜åˆ¶çŸ©å½¢
- drawCircle(x, y, radius, options) - ç»˜åˆ¶åœ†å½¢
- addText(text, x, y, options) - æ·»åŠ æ–‡æœ¬
- loadImage(imageUrl, x, y) - åŠ è½½å›¾åƒ

**é€‰é¡¹å‚æ•°ï¼š**
- fill: å¡«å……è‰² (å¦‚ '#ff0000', 'red', 'transparent')
- stroke: è¾¹æ¡†è‰²
- strokeWidth: è¾¹æ¡†å®½åº¦
- fontSize: å­—ä½“å¤§å°
- fontFamily: å­—ä½“ ('Arial', 'Times', etc.)
- fontWeight: å­—ä½“ç²—ç»† ('normal', 'bold')

**å“åº”æ ¼å¼ï¼š**
è¯·ä»¥JSONæ ¼å¼è¿”å›å‘½ä»¤åˆ—è¡¨ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
  "explanation": "æ“ä½œè¯´æ˜",
  "commands": [
    {
      "action": "å‘½ä»¤å",
      "parameters": { å‚æ•°å¯¹è±¡ },
      "description": "æ­¥éª¤æè¿°"
    }
  ]
}

**ç¤ºä¾‹ï¼š**
ç”¨æˆ·ï¼š"åˆ›å»ºä¸€ä¸ª800x600çš„ç”»å¸ƒï¼Œç”»ä¸€ä¸ªçº¢è‰²åœ†å½¢"
å“åº”ï¼š
{
  "explanation": "åˆ›å»ºç”»å¸ƒå¹¶ç»˜åˆ¶çº¢è‰²åœ†å½¢",
  "commands": [
    {
      "action": "setCanvasSize",
      "parameters": { "width": 800, "height": 600 },
      "description": "è®¾ç½®ç”»å¸ƒå°ºå¯¸ä¸º800x600"
    },
    {
      "action": "drawCircle", 
      "parameters": { "x": 400, "y": 300, "radius": 100, "options": { "fill": "#ff0000", "stroke": "#000000", "strokeWidth": 2 }},
      "description": "åœ¨ç”»å¸ƒä¸­å¿ƒç»˜åˆ¶çº¢è‰²åœ†å½¢"
    }
  ]
}

è¯·ç¡®ä¿ï¼š
1. åæ ‡å’Œå°ºå¯¸åˆç†ï¼ˆç”»å¸ƒèŒƒå›´å†…ï¼‰
2. é¢œè‰²æ ¼å¼æ­£ç¡®ï¼ˆåå…­è¿›åˆ¶æˆ–é¢œè‰²åï¼‰
3. å‚æ•°ç±»å‹æ­£ç¡®ï¼ˆæ•°å­—ã€å­—ç¬¦ä¸²ã€å¯¹è±¡ï¼‰
4. æ“ä½œé¡ºåºé€»è¾‘åˆç†
5. æä¾›æ¸…æ™°çš„ä¸­æ–‡è¯´æ˜`
  }

  /**
   * è§£æç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤
   */
  async parseNaturalLanguage(userInput: string): Promise<ParsedCommands> {
    try {
      const completion = await this.openai.chat.completions.create({
        model: this.config.model!,
        messages: [
          { role: 'system', content: this.getSystemPrompt() },
          { role: 'user', content: userInput }
        ],
        max_tokens: this.config.maxTokens,
        temperature: this.config.temperature
      })

      const response = completion.choices[0]?.message?.content
      if (!response) {
        return {
          success: false,
          commands: [],
          explanation: '',
          error: 'DeepSeekè¿”å›ç©ºå“åº”'
        }
      }

      // è§£æJSONå“åº”
      try {
        const parsed = JSON.parse(response)
        
        if (!parsed.commands || !Array.isArray(parsed.commands)) {
          return {
            success: false,
            commands: [],
            explanation: '',
            error: 'å“åº”æ ¼å¼ä¸æ­£ç¡®ï¼šç¼ºå°‘commandsæ•°ç»„'
          }
        }

        return {
          success: true,
          commands: parsed.commands,
          explanation: parsed.explanation || 'æ‰§è¡Œç”¨æˆ·æŒ‡ä»¤',
          error: undefined
        }
      } catch (parseError) {
        return {
          success: false,
          commands: [],
          explanation: '',
          error: `JSONè§£æå¤±è´¥: ${parseError}`
        }
      }

    } catch (error) {
      return {
        success: false,
        commands: [],
        explanation: '',
        error: `DeepSeek APIè°ƒç”¨å¤±è´¥: ${error}`
      }
    }
  }

  /**
   * æ‰§è¡Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤
   */
  async executeNaturalLanguage(userInput: string) {
    console.log(`ğŸ¤– DeepSeekå¤„ç†æŒ‡ä»¤: "${userInput}"`)
    
    // 1. è§£æè‡ªç„¶è¯­è¨€
    const parseResult = await this.parseNaturalLanguage(userInput)
    
    if (!parseResult.success) {
      return {
        success: false,
        message: `æŒ‡ä»¤è§£æå¤±è´¥: ${parseResult.error}`,
        error: parseResult.error
      }
    }

    console.log(`ğŸ“ è§£æç»“æœ: ${parseResult.explanation}`)
    console.log(`ğŸ”§ ç”Ÿæˆå‘½ä»¤æ•°é‡: ${parseResult.commands.length}`)

    // 2. æ‰§è¡ŒAPIå‘½ä»¤
    try {
      const results = await this.llmInterface.executeBatch(parseResult.commands)
      
      const failedResults = results.filter(r => !r.success)
      const successCount = results.length - failedResults.length

      if (failedResults.length === 0) {
        return {
          success: true,
          message: `âœ… æˆåŠŸæ‰§è¡Œ ${successCount} ä¸ªæ“ä½œ: ${parseResult.explanation}`,
          data: {
            explanation: parseResult.explanation,
            commandCount: results.length,
            results: results
          }
        }
      } else {
        return {
          success: false,
          message: `âš ï¸ éƒ¨åˆ†æ“ä½œå¤±è´¥: ${successCount}/${results.length} æˆåŠŸ`,
          error: `å¤±è´¥çš„æ“ä½œ: ${failedResults.map(r => r.message).join(', ')}`,
          data: {
            explanation: parseResult.explanation,
            commandCount: results.length,
            results: results
          }
        }
      }

    } catch (error) {
      return {
        success: false,
        message: `APIæ‰§è¡Œå¤±è´¥: ${error}`,
        error: String(error)
      }
    }
  }

  /**
   * è·å–å»ºè®®çš„æŒ‡ä»¤ç¤ºä¾‹
   */
  getSuggestedPrompts(): string[] {
    return [
      "åˆ›å»ºä¸€ä¸ª800x600çš„ç”»å¸ƒï¼ŒèƒŒæ™¯è®¾ä¸ºæµ…è“è‰²",
      "ç”»ä¸€ä¸ªçº¢è‰²çš„åœ†å½¢åœ¨ç”»å¸ƒä¸­å¿ƒ",
      "æ·»åŠ æ–‡å­—'Hello AI'åœ¨åæ ‡(200,100)ä½ç½®",
      "åˆ›å»ºä¸€ä¸ªç®€å•çš„Logoï¼šè“è‰²åœ†å½¢èƒŒæ™¯ï¼Œç™½è‰²æ–‡å­—'AI Corp'",
      "ç”»ä¸‰ä¸ªä¸åŒé¢œè‰²çš„çŸ©å½¢ï¼Œæ°´å¹³æ’åˆ—",
      "è®¾è®¡ä¸€ä¸ªå½©è™¹ï¼šç”»7ä¸ªä¸åŒé¢œè‰²çš„åœ†å½¢å¼§çº¿",
      "åˆ›å»ºä¸€ä¸ªåç‰‡è®¾è®¡ï¼šç™½è‰²èƒŒæ™¯ï¼Œé»‘è‰²è¾¹æ¡†ï¼Œå±…ä¸­æ–‡å­—",
      "ç”»ä¸€ä¸ªç®€å•çš„æˆ¿å­ï¼šçŸ©å½¢æˆ¿èº«ï¼Œä¸‰è§’å½¢å±‹é¡¶",
      "åˆ¶ä½œä¸€ä¸ªè¿›åº¦æ¡ï¼šç°è‰²èƒŒæ™¯ï¼Œç»¿è‰²å¡«å……50%",
      "è®¾è®¡ä¸€ä¸ªç®€å•çš„å›¾æ ‡ï¼šåœ†å½¢èƒŒæ™¯ï¼ŒåŠ å·ç¬¦å·"
    ]
  }

  /**
   * é”€æ¯é€‚é…å™¨
   */
  destroy() {
    this.llmInterface.destroy()
  }
}

/**
 * åˆ›å»ºDeepSeeké€‚é…å™¨å®ä¾‹
 */
export function createDeepSeekAdapter(apiKey: string, config?: Partial<DeepSeekConfig>) {
  return new DeepSeekAdapter({
    apiKey,
    ...config
  })
}

/**
 * å…¨å±€DeepSeeké€‚é…å™¨å®ä¾‹ï¼ˆéœ€è¦API Keyåˆå§‹åŒ–ï¼‰
 */
let globalAdapter: DeepSeekAdapter | null = null

export function initializeDeepSeek(apiKey: string, config?: Partial<DeepSeekConfig>) {
  globalAdapter = createDeepSeekAdapter(apiKey, config)
  return globalAdapter
}

export function getDeepSeekAdapter(): DeepSeekAdapter | null {
  return globalAdapter
}

export function destroyDeepSeek() {
  if (globalAdapter) {
    globalAdapter.destroy()
    globalAdapter = null
  }
}